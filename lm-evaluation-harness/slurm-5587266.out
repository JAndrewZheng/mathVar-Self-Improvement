2025-10-21:17:04:59 INFO     [__main__:450] Selected Tasks: ['aime']
2025-10-21:17:04:59 WARNING  [evaluator:172] pretrained=pretrained=Qwen/Qwen2.5-7B-Instruct appears to be an instruct or chat variant but chat template is not applied. Recommend setting
        `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-10-21:17:04:59 INFO     [evaluator:202] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-10-21:17:04:59 WARNING  [evaluator:214] generation_kwargs: {'max_gen_toks': 32767} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-10-21:17:04:59 INFO     [evaluator:240] Initializing hf model, with arguments: {'pretrained': 'Qwen/Qwen2.5-7B-Instruct'}
2025-10-21:17:04:59 WARNING  [accelerate.utils.other:513] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-10-21:17:04:59 INFO     [models.huggingface:156] Using device 'cuda:0'
2025-10-21:17:04:59 INFO     [models.huggingface:423] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:07<00:22,  7.51s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:14<00:14,  7.39s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:22<00:07,  7.35s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:28<00:00,  7.08s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:28<00:00,  7.20s/it]
2025-10-21:17:05:29 INFO     [evaluator:305] aime: Using gen_kwargs: {'until': ['Question:', '</s>', '<|im_end|>', '<|eot_id|>'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 32767}
2025-10-21:17:05:29 INFO     [api.task:434] Building contexts for aime on rank 0...
  0%|          | 0/933 [00:00<?, ?it/s] 33%|███▎      | 310/933 [00:00<00:00, 3097.70it/s] 68%|██████▊   | 633/933 [00:00<00:00, 3170.91it/s]100%|██████████| 933/933 [00:00<00:00, 3191.86it/s]
2025-10-21:17:05:30 INFO     [evaluator:574] Running generate_until requests
Running generate_until requests:   0%|          | 0/933 [00:00<?, ?it/s]2025-10-21:17:05:30 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 1305, truncating to last 1 tokens. Some content will be lost.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Running generate_until requests:   0%|          | 1/933 [00:15<3:55:53, 15.19s/it]2025-10-21:17:05:45 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 495, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:   1%|          | 9/933 [00:29<43:23,  2.82s/it]  2025-10-21:17:05:59 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 398, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:   2%|▏         | 17/933 [00:42<33:37,  2.20s/it]2025-10-21:17:06:13 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 357, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:   3%|▎         | 25/933 [00:56<30:09,  1.99s/it]2025-10-21:17:06:27 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 307, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:   4%|▎         | 33/933 [01:10<28:23,  1.89s/it]2025-10-21:17:06:40 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 243, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:   4%|▍         | 41/933 [01:24<27:16,  1.83s/it]2025-10-21:17:06:54 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 232, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:   5%|▌         | 49/933 [01:38<26:31,  1.80s/it]2025-10-21:17:07:08 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 221, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:   6%|▌         | 57/933 [01:52<25:56,  1.78s/it]2025-10-21:17:07:22 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 206, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:   7%|▋         | 65/933 [02:06<25:29,  1.76s/it]2025-10-21:17:07:36 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 195, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:   8%|▊         | 73/933 [02:19<25:07,  1.75s/it]2025-10-21:17:07:50 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 190, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:   9%|▊         | 81/933 [02:33<24:46,  1.74s/it]2025-10-21:17:08:04 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 186, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  10%|▉         | 89/933 [02:47<24:28,  1.74s/it]2025-10-21:17:08:17 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 182, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  10%|█         | 97/933 [03:01<24:13,  1.74s/it]2025-10-21:17:08:31 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 178, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  11%|█▏        | 105/933 [03:15<23:55,  1.73s/it]2025-10-21:17:08:45 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 174, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  12%|█▏        | 113/933 [03:29<23:40,  1.73s/it]2025-10-21:17:08:59 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 172, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  13%|█▎        | 121/933 [03:42<23:24,  1.73s/it]2025-10-21:17:09:13 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 168, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  14%|█▍        | 129/933 [03:56<23:09,  1.73s/it]2025-10-21:17:09:26 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 166, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  15%|█▍        | 137/933 [04:10<22:54,  1.73s/it]2025-10-21:17:09:40 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 163, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  16%|█▌        | 145/933 [04:24<22:40,  1.73s/it]2025-10-21:17:09:54 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 160, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  16%|█▋        | 153/933 [04:38<22:25,  1.72s/it]2025-10-21:17:10:08 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 158, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  17%|█▋        | 161/933 [04:51<22:11,  1.72s/it]2025-10-21:17:10:22 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 154, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  18%|█▊        | 169/933 [05:05<21:56,  1.72s/it]2025-10-21:17:10:35 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 152, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  19%|█▉        | 177/933 [05:19<21:42,  1.72s/it]2025-10-21:17:10:49 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 149, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  20%|█▉        | 185/933 [05:33<21:28,  1.72s/it]2025-10-21:17:11:03 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 147, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  21%|██        | 193/933 [05:46<21:14,  1.72s/it]2025-10-21:17:11:17 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 146, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  22%|██▏       | 201/933 [06:00<21:00,  1.72s/it]2025-10-21:17:11:30 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 145, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  22%|██▏       | 209/933 [06:14<20:46,  1.72s/it]2025-10-21:17:11:44 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 141, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  23%|██▎       | 217/933 [06:28<20:31,  1.72s/it]2025-10-21:17:11:58 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 138, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  24%|██▍       | 225/933 [06:41<20:18,  1.72s/it]2025-10-21:17:12:12 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 136, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  25%|██▍       | 233/933 [06:55<20:04,  1.72s/it]2025-10-21:17:12:25 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 134, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  26%|██▌       | 241/933 [07:09<19:51,  1.72s/it]2025-10-21:17:12:39 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 132, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  27%|██▋       | 249/933 [07:23<19:38,  1.72s/it]2025-10-21:17:12:53 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 130, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  28%|██▊       | 257/933 [07:37<19:23,  1.72s/it]2025-10-21:17:13:07 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 129, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  28%|██▊       | 265/933 [07:50<19:10,  1.72s/it]2025-10-21:17:13:21 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 127, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  29%|██▉       | 273/933 [08:04<18:55,  1.72s/it]2025-10-21:17:13:34 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 126, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  30%|███       | 281/933 [08:18<18:41,  1.72s/it]2025-10-21:17:13:48 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 124, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  31%|███       | 289/933 [08:32<18:28,  1.72s/it]2025-10-21:17:14:02 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 123, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  32%|███▏      | 297/933 [08:45<18:14,  1.72s/it]2025-10-21:17:14:16 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 121, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  33%|███▎      | 305/933 [08:59<18:01,  1.72s/it]2025-10-21:17:14:29 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 119, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  34%|███▎      | 313/933 [09:13<17:48,  1.72s/it]2025-10-21:17:14:43 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 118, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  34%|███▍      | 321/933 [09:27<17:34,  1.72s/it]2025-10-21:17:14:57 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 117, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  35%|███▌      | 329/933 [09:41<17:19,  1.72s/it]2025-10-21:17:15:11 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 116, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  36%|███▌      | 337/933 [09:54<17:06,  1.72s/it]2025-10-21:17:15:25 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 115, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  37%|███▋      | 345/933 [10:08<16:52,  1.72s/it]2025-10-21:17:15:38 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 114, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  38%|███▊      | 353/933 [10:22<16:37,  1.72s/it]2025-10-21:17:15:52 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 113, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  39%|███▊      | 361/933 [10:36<16:24,  1.72s/it]2025-10-21:17:16:06 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 111, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  40%|███▉      | 369/933 [10:49<16:10,  1.72s/it]2025-10-21:17:16:20 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 110, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  40%|████      | 377/933 [11:03<15:56,  1.72s/it]2025-10-21:17:16:33 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 109, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  41%|████▏     | 385/933 [11:17<15:42,  1.72s/it]2025-10-21:17:16:47 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 108, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  42%|████▏     | 393/933 [11:31<15:29,  1.72s/it]2025-10-21:17:17:01 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 107, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  43%|████▎     | 401/933 [11:44<15:14,  1.72s/it]2025-10-21:17:17:15 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 106, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  44%|████▍     | 409/933 [11:58<15:00,  1.72s/it]2025-10-21:17:17:28 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 105, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  45%|████▍     | 417/933 [12:12<14:47,  1.72s/it]2025-10-21:17:17:42 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 103, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  46%|████▌     | 425/933 [12:26<14:32,  1.72s/it]2025-10-21:17:17:56 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 102, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  46%|████▋     | 433/933 [12:39<14:18,  1.72s/it]2025-10-21:17:18:10 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 101, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  47%|████▋     | 441/933 [12:53<14:05,  1.72s/it]2025-10-21:17:18:23 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 101, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  48%|████▊     | 449/933 [13:07<13:51,  1.72s/it]2025-10-21:17:18:37 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 100, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  49%|████▉     | 457/933 [13:21<13:37,  1.72s/it]2025-10-21:17:18:51 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 98, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  50%|████▉     | 465/933 [13:34<13:23,  1.72s/it]2025-10-21:17:19:05 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 97, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  51%|█████     | 473/933 [13:48<13:10,  1.72s/it]2025-10-21:17:19:18 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 96, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  52%|█████▏    | 481/933 [14:02<12:56,  1.72s/it]2025-10-21:17:19:32 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 95, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  52%|█████▏    | 489/933 [14:15<12:42,  1.72s/it]2025-10-21:17:19:46 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 94, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  53%|█████▎    | 497/933 [14:29<12:29,  1.72s/it]2025-10-21:17:20:00 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 93, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  54%|█████▍    | 505/933 [14:43<12:15,  1.72s/it]2025-10-21:17:20:13 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 92, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  55%|█████▍    | 513/933 [14:57<12:01,  1.72s/it]2025-10-21:17:20:27 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 92, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  56%|█████▌    | 521/933 [15:11<11:48,  1.72s/it]2025-10-21:17:20:41 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 91, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  57%|█████▋    | 529/933 [15:24<11:34,  1.72s/it]2025-10-21:17:20:55 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 90, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  58%|█████▊    | 537/933 [15:38<11:20,  1.72s/it]2025-10-21:17:21:08 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 89, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  58%|█████▊    | 545/933 [15:52<11:06,  1.72s/it]2025-10-21:17:21:22 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 88, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  59%|█████▉    | 553/933 [16:05<10:52,  1.72s/it]2025-10-21:17:21:36 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 87, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  60%|██████    | 561/933 [16:19<10:39,  1.72s/it]2025-10-21:17:21:49 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 86, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  61%|██████    | 569/933 [16:33<10:25,  1.72s/it]2025-10-21:17:22:03 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 85, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  62%|██████▏   | 577/933 [16:47<10:11,  1.72s/it]2025-10-21:17:22:17 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 84, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  63%|██████▎   | 585/933 [17:01<09:58,  1.72s/it]2025-10-21:17:22:31 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 83, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  64%|██████▎   | 593/933 [17:14<09:45,  1.72s/it]2025-10-21:17:22:45 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 82, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  64%|██████▍   | 601/933 [17:28<09:31,  1.72s/it]2025-10-21:17:22:58 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 81, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  65%|██████▌   | 609/933 [17:42<09:17,  1.72s/it]2025-10-21:17:23:12 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 80, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  66%|██████▌   | 617/933 [17:56<09:04,  1.72s/it]2025-10-21:17:23:26 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 80, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  67%|██████▋   | 625/933 [18:09<08:50,  1.72s/it]2025-10-21:17:23:40 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 78, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  68%|██████▊   | 633/933 [18:23<08:36,  1.72s/it]2025-10-21:17:23:53 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 77, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  69%|██████▊   | 641/933 [18:37<08:22,  1.72s/it]2025-10-21:17:24:07 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 77, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  70%|██████▉   | 649/933 [18:51<08:08,  1.72s/it]2025-10-21:17:24:21 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 76, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  70%|███████   | 657/933 [19:04<07:55,  1.72s/it]2025-10-21:17:24:35 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 75, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  71%|███████▏  | 665/933 [19:18<07:41,  1.72s/it]2025-10-21:17:24:48 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 74, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  72%|███████▏  | 673/933 [19:32<07:27,  1.72s/it]2025-10-21:17:25:02 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 73, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  73%|███████▎  | 681/933 [19:46<07:13,  1.72s/it]2025-10-21:17:25:16 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 72, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  74%|███████▍  | 689/933 [20:00<07:00,  1.72s/it]2025-10-21:17:25:30 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 71, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  75%|███████▍  | 697/933 [20:13<06:46,  1.72s/it]2025-10-21:17:25:44 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 70, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  76%|███████▌  | 705/933 [20:27<06:32,  1.72s/it]2025-10-21:17:25:57 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 69, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  76%|███████▋  | 713/933 [20:41<06:18,  1.72s/it]2025-10-21:17:26:11 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 68, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  77%|███████▋  | 721/933 [20:55<06:04,  1.72s/it]2025-10-21:17:26:25 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 67, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  78%|███████▊  | 729/933 [21:08<05:51,  1.72s/it]2025-10-21:17:26:39 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 67, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  79%|███████▉  | 737/933 [21:22<05:37,  1.72s/it]2025-10-21:17:26:52 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 66, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  80%|███████▉  | 745/933 [21:36<05:23,  1.72s/it]2025-10-21:17:27:06 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 64, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  81%|████████  | 753/933 [21:50<05:09,  1.72s/it]2025-10-21:17:27:20 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 63, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  82%|████████▏ | 761/933 [22:03<04:55,  1.72s/it]2025-10-21:17:27:34 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 62, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  82%|████████▏ | 769/933 [22:17<04:42,  1.72s/it]2025-10-21:17:27:47 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 62, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  83%|████████▎ | 777/933 [22:31<04:28,  1.72s/it]2025-10-21:17:28:01 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 60, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  84%|████████▍ | 785/933 [22:45<04:14,  1.72s/it]2025-10-21:17:28:15 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 60, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  85%|████████▍ | 793/933 [22:59<04:00,  1.72s/it]2025-10-21:17:28:29 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 58, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  86%|████████▌ | 801/933 [23:12<03:47,  1.72s/it]2025-10-21:17:28:43 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 56, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  87%|████████▋ | 809/933 [23:26<03:33,  1.72s/it]2025-10-21:17:28:56 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 55, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  88%|████████▊ | 817/933 [23:40<03:19,  1.72s/it]2025-10-21:17:29:10 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 53, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  88%|████████▊ | 825/933 [23:54<03:05,  1.72s/it]2025-10-21:17:29:24 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 52, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  89%|████████▉ | 833/933 [24:07<02:52,  1.72s/it]2025-10-21:17:29:38 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 51, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  90%|█████████ | 841/933 [24:21<02:38,  1.72s/it]2025-10-21:17:29:51 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 50, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  91%|█████████ | 849/933 [24:35<02:24,  1.72s/it]2025-10-21:17:30:05 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 48, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  92%|█████████▏| 857/933 [24:49<02:10,  1.72s/it]2025-10-21:17:30:19 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 47, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  93%|█████████▎| 865/933 [25:02<01:56,  1.72s/it]2025-10-21:17:30:33 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 45, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  94%|█████████▎| 873/933 [25:16<01:43,  1.72s/it]2025-10-21:17:30:46 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 44, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  94%|█████████▍| 881/933 [25:30<01:29,  1.72s/it]2025-10-21:17:31:00 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 41, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  95%|█████████▌| 889/933 [25:44<01:15,  1.72s/it]2025-10-21:17:31:14 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 38, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  96%|█████████▌| 897/933 [25:57<01:01,  1.72s/it]2025-10-21:17:31:28 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 36, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  97%|█████████▋| 905/933 [26:11<00:48,  1.72s/it]2025-10-21:17:31:42 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 34, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  98%|█████████▊| 913/933 [26:25<00:34,  1.72s/it]2025-10-21:17:31:55 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 32, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  99%|█████████▊| 921/933 [26:39<00:20,  1.72s/it]2025-10-21:17:32:09 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 24, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests: 100%|█████████▉| 929/933 [26:54<00:07,  1.78s/it]Running generate_until requests: 100%|██████████| 933/933 [26:54<00:00,  1.73s/it]
2025-10-21:17:32:32 INFO     [loggers.evaluation_tracker:280] Output path not provided, skipping saving results aggregated
hf (pretrained=Qwen/Qwen2.5-7B-Instruct), gen_kwargs: ({'max_gen_toks': 32767}), limit: None, num_fewshot: None, batch_size: 8
|Tasks|Version|Filter|n-shot|  Metric   |   |Value|   |Stderr|
|-----|------:|------|-----:|-----------|---|----:|---|-----:|
|aime |      0|none  |     0|exact_match|↑  |    0|±  |     0|

