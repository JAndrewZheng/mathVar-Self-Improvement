2025-10-22:12:18:43 INFO     [__main__:450] Selected Tasks: ['aime24']
2025-10-22:12:18:43 INFO     [evaluator:202] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-10-22:12:18:43 WARNING  [evaluator:214] generation_kwargs: {'max_gen_toks': 32767} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-10-22:12:18:43 INFO     [evaluator:240] Initializing hf model, with arguments: {'pretrained': 'Qwen/Qwen2.5-7B-Instruct'}
2025-10-22:12:18:43 WARNING  [accelerate.utils.other:513] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-10-22:12:18:43 INFO     [models.huggingface:156] Using device 'cuda:0'
2025-10-22:12:18:44 INFO     [models.huggingface:423] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:11<00:35, 11.98s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:18<00:18,  9.06s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:27<00:08,  8.69s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:35<00:00,  8.36s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:35<00:00,  8.77s/it]
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 30 examples [00:00, 460.40 examples/s]
2025-10-22:12:19:22 INFO     [evaluator:305] aime24: Using gen_kwargs: {'until': ['Question:', '</s>', '<|im_end|>', '<|eot_id|>'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 32767}
2025-10-22:12:19:22 INFO     [evaluator:320] num_fewshot has been set to 0 for aime24 in its config. Manual configuration will be ignored.
2025-10-22:12:19:22 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-10-22:12:19:22 INFO     [api.task:434] Building contexts for aime24 on rank 0...
  0%|          | 0/30 [00:00<?, ?it/s]100%|██████████| 30/30 [00:00<00:00, 1193.38it/s]
2025-10-22:12:19:22 INFO     [evaluator:574] Running generate_until requests
Running generate_until requests:   0%|          | 0/30 [00:00<?, ?it/s]2025-10-22:12:19:22 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 388, truncating to last 1 tokens. Some content will be lost.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Running generate_until requests:   3%|▎         | 1/30 [00:17<08:34, 17.75s/it]2025-10-22:12:19:40 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 156, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  30%|███       | 9/30 [00:33<01:07,  3.23s/it]2025-10-22:12:19:55 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 110, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  57%|█████▋    | 17/30 [00:49<00:32,  2.50s/it]2025-10-22:12:20:11 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 94, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  83%|████████▎ | 25/30 [01:03<00:10,  2.19s/it]Running generate_until requests: 100%|██████████| 30/30 [01:03<00:00,  2.12s/it]
2025-10-22:12:20:34 INFO     [loggers.evaluation_tracker:280] Output path not provided, skipping saving results aggregated
hf (pretrained=Qwen/Qwen2.5-7B-Instruct), gen_kwargs: ({'max_gen_toks': 32767}), limit: None, num_fewshot: 0, batch_size: 8
|Tasks |Version|Filter|n-shot|  Metric   |   |Value|   |Stderr|
|------|------:|------|-----:|-----------|---|----:|---|-----:|
|aime24|      0|none  |     0|exact_match|↑  |    0|±  |     0|

