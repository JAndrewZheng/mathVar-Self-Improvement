2025-10-22:12:42:46 INFO     [__main__:450] Selected Tasks: ['aime']
2025-10-22:12:42:46 INFO     [evaluator:202] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-10-22:12:42:46 WARNING  [evaluator:214] generation_kwargs: {'max_gen_toks': 2048} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-10-22:12:42:46 INFO     [evaluator:240] Initializing hf model, with arguments: {'pretrained': 'Qwen/Qwen2.5-Math-7B'}
2025-10-22:12:42:46 WARNING  [accelerate.utils.other:513] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-10-22:12:42:46 INFO     [models.huggingface:156] Using device 'cuda:0'
2025-10-22:12:42:46 INFO     [models.huggingface:423] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  1.93it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.93it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  1.86it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.95it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.93it/s]
2025-10-22:12:42:49 INFO     [evaluator:305] aime: Using gen_kwargs: {'until': ['Question:', '</s>', '<|im_end|>', '<|eot_id|>'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 2048}
2025-10-22:12:42:49 INFO     [evaluator:320] num_fewshot has been set to 0 for aime in its config. Manual configuration will be ignored.
2025-10-22:12:42:49 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-10-22:12:42:49 INFO     [api.task:434] Building contexts for aime on rank 0...
  0%|          | 0/933 [00:00<?, ?it/s] 26%|██▌       | 239/933 [00:00<00:00, 2387.34it/s] 56%|█████▌    | 522/933 [00:00<00:00, 2642.59it/s] 86%|████████▋ | 806/933 [00:00<00:00, 2730.25it/s]100%|██████████| 933/933 [00:00<00:00, 2701.37it/s]
2025-10-22:12:42:50 INFO     [evaluator:574] Running generate_until requests
Running generate_until requests:   0%|          | 0/933 [00:00<?, ?it/s]Both `max_new_tokens` (=2048) and `max_length`(=3381) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:   0%|          | 1/933 [02:18<35:50:50, 138.47s/it]Both `max_new_tokens` (=2048) and `max_length`(=2571) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:   1%|          | 9/933 [04:09<6:07:38, 23.87s/it]  Both `max_new_tokens` (=2048) and `max_length`(=2474) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:   2%|▏         | 17/933 [05:56<4:34:02, 17.95s/it]Both `max_new_tokens` (=2048) and `max_length`(=2433) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:   3%|▎         | 25/933 [07:42<3:59:59, 15.86s/it]Both `max_new_tokens` (=2048) and `max_length`(=2383) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:   4%|▎         | 33/933 [09:27<3:41:34, 14.77s/it]Both `max_new_tokens` (=2048) and `max_length`(=2319) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:   4%|▍         | 41/933 [11:10<3:29:09, 14.07s/it]Both `max_new_tokens` (=2048) and `max_length`(=2308) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:   5%|▌         | 49/933 [12:52<3:20:48, 13.63s/it]Both `max_new_tokens` (=2048) and `max_length`(=2297) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:   6%|▌         | 57/933 [13:50<2:49:00, 11.58s/it]Both `max_new_tokens` (=2048) and `max_length`(=2282) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:   7%|▋         | 65/933 [15:32<2:52:29, 11.92s/it]Both `max_new_tokens` (=2048) and `max_length`(=2271) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:   8%|▊         | 73/933 [17:12<2:53:48, 12.13s/it]Both `max_new_tokens` (=2048) and `max_length`(=2266) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:   9%|▊         | 81/933 [18:53<2:54:07, 12.26s/it]Both `max_new_tokens` (=2048) and `max_length`(=2262) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  10%|▉         | 89/933 [20:33<2:53:37, 12.34s/it]Both `max_new_tokens` (=2048) and `max_length`(=2258) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  10%|█         | 97/933 [22:13<2:52:42, 12.40s/it]Both `max_new_tokens` (=2048) and `max_length`(=2254) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  11%|█▏        | 105/933 [23:53<2:51:29, 12.43s/it]Both `max_new_tokens` (=2048) and `max_length`(=2250) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  12%|█▏        | 113/933 [25:33<2:50:03, 12.44s/it]Both `max_new_tokens` (=2048) and `max_length`(=2248) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  13%|█▎        | 121/933 [27:13<2:48:31, 12.45s/it]Both `max_new_tokens` (=2048) and `max_length`(=2244) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  14%|█▍        | 129/933 [28:52<2:46:54, 12.46s/it]Both `max_new_tokens` (=2048) and `max_length`(=2242) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  15%|█▍        | 137/933 [30:31<2:44:33, 12.40s/it]Both `max_new_tokens` (=2048) and `max_length`(=2239) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  16%|█▌        | 145/933 [32:10<2:43:04, 12.42s/it]Both `max_new_tokens` (=2048) and `max_length`(=2236) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  16%|█▋        | 153/933 [33:50<2:41:32, 12.43s/it]Both `max_new_tokens` (=2048) and `max_length`(=2234) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  17%|█▋        | 161/933 [35:29<2:39:49, 12.42s/it]Both `max_new_tokens` (=2048) and `max_length`(=2230) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  18%|█▊        | 169/933 [37:08<2:38:03, 12.41s/it]Both `max_new_tokens` (=2048) and `max_length`(=2228) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  19%|█▉        | 177/933 [38:47<2:36:18, 12.41s/it]Both `max_new_tokens` (=2048) and `max_length`(=2225) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  20%|█▉        | 185/933 [40:26<2:34:32, 12.40s/it]Both `max_new_tokens` (=2048) and `max_length`(=2223) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  21%|██        | 193/933 [42:05<2:32:47, 12.39s/it]Both `max_new_tokens` (=2048) and `max_length`(=2222) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  22%|██▏       | 201/933 [43:44<2:31:01, 12.38s/it]Both `max_new_tokens` (=2048) and `max_length`(=2221) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  22%|██▏       | 209/933 [45:23<2:29:16, 12.37s/it]Both `max_new_tokens` (=2048) and `max_length`(=2217) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  23%|██▎       | 217/933 [46:45<2:20:08, 11.74s/it]Both `max_new_tokens` (=2048) and `max_length`(=2214) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  24%|██▍       | 225/933 [48:01<2:10:23, 11.05s/it]Both `max_new_tokens` (=2048) and `max_length`(=2212) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
