2025-10-22:12:42:46 INFO     [__main__:450] Selected Tasks: ['aime']
2025-10-22:12:42:46 INFO     [evaluator:202] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-10-22:12:42:46 WARNING  [evaluator:214] generation_kwargs: {'max_gen_toks': 2048} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-10-22:12:42:46 INFO     [evaluator:240] Initializing hf model, with arguments: {'pretrained': 'Qwen/Qwen2.5-Math-7B'}
2025-10-22:12:42:46 WARNING  [accelerate.utils.other:513] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-10-22:12:42:46 INFO     [models.huggingface:156] Using device 'cuda:0'
2025-10-22:12:42:46 INFO     [models.huggingface:423] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:01,  1.93it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.93it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  1.86it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.95it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.93it/s]
2025-10-22:12:42:49 INFO     [evaluator:305] aime: Using gen_kwargs: {'until': ['Question:', '</s>', '<|im_end|>', '<|eot_id|>'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 2048}
2025-10-22:12:42:49 INFO     [evaluator:320] num_fewshot has been set to 0 for aime in its config. Manual configuration will be ignored.
2025-10-22:12:42:49 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-10-22:12:42:49 INFO     [api.task:434] Building contexts for aime on rank 0...
  0%|          | 0/933 [00:00<?, ?it/s] 26%|██▌       | 239/933 [00:00<00:00, 2387.34it/s] 56%|█████▌    | 522/933 [00:00<00:00, 2642.59it/s] 86%|████████▋ | 806/933 [00:00<00:00, 2730.25it/s]100%|██████████| 933/933 [00:00<00:00, 2701.37it/s]
2025-10-22:12:42:50 INFO     [evaluator:574] Running generate_until requests
Running generate_until requests:   0%|          | 0/933 [00:00<?, ?it/s]Both `max_new_tokens` (=2048) and `max_length`(=3381) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:   0%|          | 1/933 [02:18<35:50:50, 138.47s/it]Both `max_new_tokens` (=2048) and `max_length`(=2571) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:   1%|          | 9/933 [04:09<6:07:38, 23.87s/it]  Both `max_new_tokens` (=2048) and `max_length`(=2474) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:   2%|▏         | 17/933 [05:56<4:34:02, 17.95s/it]Both `max_new_tokens` (=2048) and `max_length`(=2433) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:   3%|▎         | 25/933 [07:42<3:59:59, 15.86s/it]Both `max_new_tokens` (=2048) and `max_length`(=2383) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:   4%|▎         | 33/933 [09:27<3:41:34, 14.77s/it]Both `max_new_tokens` (=2048) and `max_length`(=2319) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:   4%|▍         | 41/933 [11:10<3:29:09, 14.07s/it]Both `max_new_tokens` (=2048) and `max_length`(=2308) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:   5%|▌         | 49/933 [12:52<3:20:48, 13.63s/it]Both `max_new_tokens` (=2048) and `max_length`(=2297) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:   6%|▌         | 57/933 [13:50<2:49:00, 11.58s/it]Both `max_new_tokens` (=2048) and `max_length`(=2282) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:   7%|▋         | 65/933 [15:32<2:52:29, 11.92s/it]Both `max_new_tokens` (=2048) and `max_length`(=2271) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:   8%|▊         | 73/933 [17:12<2:53:48, 12.13s/it]Both `max_new_tokens` (=2048) and `max_length`(=2266) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:   9%|▊         | 81/933 [18:53<2:54:07, 12.26s/it]Both `max_new_tokens` (=2048) and `max_length`(=2262) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  10%|▉         | 89/933 [20:33<2:53:37, 12.34s/it]Both `max_new_tokens` (=2048) and `max_length`(=2258) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  10%|█         | 97/933 [22:13<2:52:42, 12.40s/it]Both `max_new_tokens` (=2048) and `max_length`(=2254) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  11%|█▏        | 105/933 [23:53<2:51:29, 12.43s/it]Both `max_new_tokens` (=2048) and `max_length`(=2250) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  12%|█▏        | 113/933 [25:33<2:50:03, 12.44s/it]Both `max_new_tokens` (=2048) and `max_length`(=2248) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  13%|█▎        | 121/933 [27:13<2:48:31, 12.45s/it]Both `max_new_tokens` (=2048) and `max_length`(=2244) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  14%|█▍        | 129/933 [28:52<2:46:54, 12.46s/it]Both `max_new_tokens` (=2048) and `max_length`(=2242) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  15%|█▍        | 137/933 [30:31<2:44:33, 12.40s/it]Both `max_new_tokens` (=2048) and `max_length`(=2239) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  16%|█▌        | 145/933 [32:10<2:43:04, 12.42s/it]Both `max_new_tokens` (=2048) and `max_length`(=2236) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  16%|█▋        | 153/933 [33:50<2:41:32, 12.43s/it]Both `max_new_tokens` (=2048) and `max_length`(=2234) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  17%|█▋        | 161/933 [35:29<2:39:49, 12.42s/it]Both `max_new_tokens` (=2048) and `max_length`(=2230) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  18%|█▊        | 169/933 [37:08<2:38:03, 12.41s/it]Both `max_new_tokens` (=2048) and `max_length`(=2228) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  19%|█▉        | 177/933 [38:47<2:36:18, 12.41s/it]Both `max_new_tokens` (=2048) and `max_length`(=2225) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  20%|█▉        | 185/933 [40:26<2:34:32, 12.40s/it]Both `max_new_tokens` (=2048) and `max_length`(=2223) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  21%|██        | 193/933 [42:05<2:32:47, 12.39s/it]Both `max_new_tokens` (=2048) and `max_length`(=2222) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  22%|██▏       | 201/933 [43:44<2:31:01, 12.38s/it]Both `max_new_tokens` (=2048) and `max_length`(=2221) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  22%|██▏       | 209/933 [45:23<2:29:16, 12.37s/it]Both `max_new_tokens` (=2048) and `max_length`(=2217) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  23%|██▎       | 217/933 [46:45<2:20:08, 11.74s/it]Both `max_new_tokens` (=2048) and `max_length`(=2214) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  24%|██▍       | 225/933 [48:01<2:10:23, 11.05s/it]Both `max_new_tokens` (=2048) and `max_length`(=2212) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  25%|██▍       | 233/933 [49:29<2:09:02, 11.06s/it]Both `max_new_tokens` (=2048) and `max_length`(=2210) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  26%|██▌       | 241/933 [51:08<2:11:53, 11.44s/it]Both `max_new_tokens` (=2048) and `max_length`(=2208) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  27%|██▋       | 249/933 [52:46<2:13:19, 11.70s/it]Both `max_new_tokens` (=2048) and `max_length`(=2206) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  28%|██▊       | 257/933 [54:25<2:13:46, 11.87s/it]Both `max_new_tokens` (=2048) and `max_length`(=2205) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  28%|██▊       | 265/933 [56:03<2:13:34, 12.00s/it]Both `max_new_tokens` (=2048) and `max_length`(=2203) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  29%|██▉       | 273/933 [57:41<2:12:54, 12.08s/it]Both `max_new_tokens` (=2048) and `max_length`(=2202) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  30%|███       | 281/933 [59:19<2:11:55, 12.14s/it]Both `max_new_tokens` (=2048) and `max_length`(=2200) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  31%|███       | 289/933 [1:00:58<2:10:42, 12.18s/it]Both `max_new_tokens` (=2048) and `max_length`(=2199) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  32%|███▏      | 297/933 [1:02:36<2:09:22, 12.20s/it]Both `max_new_tokens` (=2048) and `max_length`(=2197) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  33%|███▎      | 305/933 [1:04:14<2:07:53, 12.22s/it]Both `max_new_tokens` (=2048) and `max_length`(=2195) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  34%|███▎      | 313/933 [1:05:52<2:06:23, 12.23s/it]Both `max_new_tokens` (=2048) and `max_length`(=2194) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  34%|███▍      | 321/933 [1:07:30<2:04:47, 12.23s/it]Both `max_new_tokens` (=2048) and `max_length`(=2193) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  35%|███▌      | 329/933 [1:09:08<2:03:09, 12.23s/it]Both `max_new_tokens` (=2048) and `max_length`(=2192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  36%|███▌      | 337/933 [1:10:46<2:01:35, 12.24s/it]Both `max_new_tokens` (=2048) and `max_length`(=2191) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  37%|███▋      | 345/933 [1:12:24<2:00:01, 12.25s/it]Both `max_new_tokens` (=2048) and `max_length`(=2190) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  38%|███▊      | 353/933 [1:14:02<1:58:25, 12.25s/it]Both `max_new_tokens` (=2048) and `max_length`(=2189) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  39%|███▊      | 361/933 [1:15:40<1:56:48, 12.25s/it]Both `max_new_tokens` (=2048) and `max_length`(=2187) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  40%|███▉      | 369/933 [1:17:18<1:55:09, 12.25s/it]Both `max_new_tokens` (=2048) and `max_length`(=2186) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  40%|████      | 377/933 [1:18:56<1:53:28, 12.25s/it]Both `max_new_tokens` (=2048) and `max_length`(=2185) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  41%|████▏     | 385/933 [1:20:34<1:51:50, 12.25s/it]Both `max_new_tokens` (=2048) and `max_length`(=2184) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  42%|████▏     | 393/933 [1:22:11<1:50:08, 12.24s/it]Both `max_new_tokens` (=2048) and `max_length`(=2183) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  43%|████▎     | 401/933 [1:23:49<1:48:27, 12.23s/it]Both `max_new_tokens` (=2048) and `max_length`(=2182) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  44%|████▍     | 409/933 [1:25:27<1:46:47, 12.23s/it]Both `max_new_tokens` (=2048) and `max_length`(=2181) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  45%|████▍     | 417/933 [1:27:05<1:45:10, 12.23s/it]Both `max_new_tokens` (=2048) and `max_length`(=2179) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  46%|████▌     | 425/933 [1:28:06<1:31:47, 10.84s/it]Both `max_new_tokens` (=2048) and `max_length`(=2178) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  46%|████▋     | 433/933 [1:29:06<1:22:13,  9.87s/it]Both `max_new_tokens` (=2048) and `max_length`(=2177) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  47%|████▋     | 441/933 [1:30:07<1:15:16,  9.18s/it]Both `max_new_tokens` (=2048) and `max_length`(=2177) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  48%|████▊     | 449/933 [1:31:35<1:18:21,  9.71s/it]Both `max_new_tokens` (=2048) and `max_length`(=2176) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  49%|████▉     | 457/933 [1:32:23<1:08:21,  8.62s/it]Both `max_new_tokens` (=2048) and `max_length`(=2174) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  50%|████▉     | 465/933 [1:33:24<1:04:46,  8.31s/it]Both `max_new_tokens` (=2048) and `max_length`(=2173) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  51%|█████     | 473/933 [1:34:24<1:01:59,  8.09s/it]Both `max_new_tokens` (=2048) and `max_length`(=2172) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  52%|█████▏    | 481/933 [1:36:01<1:10:02,  9.30s/it]Both `max_new_tokens` (=2048) and `max_length`(=2171) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  52%|█████▏    | 489/933 [1:37:39<1:15:08, 10.15s/it]Both `max_new_tokens` (=2048) and `max_length`(=2170) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  53%|█████▎    | 497/933 [1:39:16<1:18:07, 10.75s/it]Both `max_new_tokens` (=2048) and `max_length`(=2169) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  54%|█████▍    | 505/933 [1:40:53<1:19:42, 11.17s/it]Both `max_new_tokens` (=2048) and `max_length`(=2168) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  55%|█████▍    | 513/933 [1:41:30<1:04:27,  9.21s/it]Both `max_new_tokens` (=2048) and `max_length`(=2168) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  56%|█████▌    | 521/933 [1:43:07<1:09:13, 10.08s/it]Both `max_new_tokens` (=2048) and `max_length`(=2167) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  57%|█████▋    | 529/933 [1:44:44<1:12:01, 10.70s/it]Both `max_new_tokens` (=2048) and `max_length`(=2166) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  58%|█████▊    | 537/933 [1:46:21<1:13:25, 11.12s/it]Both `max_new_tokens` (=2048) and `max_length`(=2165) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  58%|█████▊    | 545/933 [1:47:58<1:13:52, 11.42s/it]Both `max_new_tokens` (=2048) and `max_length`(=2164) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  59%|█████▉    | 553/933 [1:49:35<1:13:40, 11.63s/it]Both `max_new_tokens` (=2048) and `max_length`(=2163) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  60%|██████    | 561/933 [1:50:35<1:04:33, 10.41s/it]Both `max_new_tokens` (=2048) and `max_length`(=2162) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  61%|██████    | 569/933 [1:52:12<1:06:15, 10.92s/it]Both `max_new_tokens` (=2048) and `max_length`(=2161) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  62%|██████▏   | 577/933 [1:53:49<1:06:54, 11.28s/it]Both `max_new_tokens` (=2048) and `max_length`(=2160) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  63%|██████▎   | 585/933 [1:55:26<1:06:50, 11.52s/it]Both `max_new_tokens` (=2048) and `max_length`(=2159) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  64%|██████▎   | 593/933 [1:57:03<1:06:16, 11.70s/it]Both `max_new_tokens` (=2048) and `max_length`(=2158) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  64%|██████▍   | 601/933 [1:58:40<1:05:23, 11.82s/it]Both `max_new_tokens` (=2048) and `max_length`(=2157) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  65%|██████▌   | 609/933 [2:00:16<1:04:14, 11.90s/it]Both `max_new_tokens` (=2048) and `max_length`(=2156) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  66%|██████▌   | 617/933 [2:01:17<55:48, 10.60s/it]  Both `max_new_tokens` (=2048) and `max_length`(=2156) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  67%|██████▋   | 625/933 [2:02:53<56:41, 11.04s/it]Both `max_new_tokens` (=2048) and `max_length`(=2154) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  68%|██████▊   | 633/933 [2:03:54<49:59, 10.00s/it]Both `max_new_tokens` (=2048) and `max_length`(=2153) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  69%|██████▊   | 641/933 [2:04:54<45:06,  9.27s/it]Both `max_new_tokens` (=2048) and `max_length`(=2153) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  70%|██████▉   | 649/933 [2:06:31<47:50, 10.11s/it]Both `max_new_tokens` (=2048) and `max_length`(=2152) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  70%|███████   | 657/933 [2:08:07<49:11, 10.69s/it]Both `max_new_tokens` (=2048) and `max_length`(=2151) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  71%|███████▏  | 665/933 [2:09:44<49:38, 11.11s/it]Both `max_new_tokens` (=2048) and `max_length`(=2150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  72%|███████▏  | 673/933 [2:11:21<49:25, 11.41s/it]Both `max_new_tokens` (=2048) and `max_length`(=2149) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  73%|███████▎  | 681/933 [2:12:58<48:45, 11.61s/it]Both `max_new_tokens` (=2048) and `max_length`(=2148) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  74%|███████▍  | 689/933 [2:14:34<47:46, 11.75s/it]Both `max_new_tokens` (=2048) and `max_length`(=2147) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  75%|███████▍  | 697/933 [2:16:11<46:35, 11.85s/it]Both `max_new_tokens` (=2048) and `max_length`(=2146) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  76%|███████▌  | 705/933 [2:17:47<45:17, 11.92s/it]Both `max_new_tokens` (=2048) and `max_length`(=2145) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  76%|███████▋  | 713/933 [2:19:24<43:51, 11.96s/it]Both `max_new_tokens` (=2048) and `max_length`(=2144) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  77%|███████▋  | 721/933 [2:21:01<42:23, 12.00s/it]Both `max_new_tokens` (=2048) and `max_length`(=2143) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  78%|███████▊  | 729/933 [2:22:01<36:16, 10.67s/it]Both `max_new_tokens` (=2048) and `max_length`(=2143) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  79%|███████▉  | 737/933 [2:23:38<36:13, 11.09s/it]Both `max_new_tokens` (=2048) and `max_length`(=2142) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  80%|███████▉  | 745/933 [2:25:14<35:39, 11.38s/it]Both `max_new_tokens` (=2048) and `max_length`(=2140) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  81%|████████  | 753/933 [2:26:51<34:44, 11.58s/it]Both `max_new_tokens` (=2048) and `max_length`(=2139) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  82%|████████▏ | 761/933 [2:28:27<33:36, 11.72s/it]Both `max_new_tokens` (=2048) and `max_length`(=2138) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  82%|████████▏ | 769/933 [2:29:27<28:37, 10.47s/it]Both `max_new_tokens` (=2048) and `max_length`(=2138) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  83%|████████▎ | 777/933 [2:31:04<28:25, 10.94s/it]Both `max_new_tokens` (=2048) and `max_length`(=2136) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  84%|████████▍ | 785/933 [2:32:04<24:28,  9.92s/it]Both `max_new_tokens` (=2048) and `max_length`(=2136) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  85%|████████▍ | 793/933 [2:33:40<24:36, 10.55s/it]Both `max_new_tokens` (=2048) and `max_length`(=2134) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  86%|████████▌ | 801/933 [2:35:16<24:09, 10.98s/it]Both `max_new_tokens` (=2048) and `max_length`(=2132) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  87%|████████▋ | 809/933 [2:36:52<23:19, 11.28s/it]Both `max_new_tokens` (=2048) and `max_length`(=2131) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  88%|████████▊ | 817/933 [2:38:28<22:13, 11.49s/it]Both `max_new_tokens` (=2048) and `max_length`(=2129) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  88%|████████▊ | 825/933 [2:39:28<18:33, 10.31s/it]Both `max_new_tokens` (=2048) and `max_length`(=2128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  89%|████████▉ | 833/933 [2:40:28<15:48,  9.48s/it]Both `max_new_tokens` (=2048) and `max_length`(=2127) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  90%|█████████ | 841/933 [2:41:29<13:38,  8.90s/it]Both `max_new_tokens` (=2048) and `max_length`(=2126) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  91%|█████████ | 849/933 [2:43:04<13:44,  9.82s/it]Both `max_new_tokens` (=2048) and `max_length`(=2124) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  92%|█████████▏| 857/933 [2:43:05<08:42,  6.88s/it]Both `max_new_tokens` (=2048) and `max_length`(=2123) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  93%|█████████▎| 864/933 [2:43:21<07:54,  6.88s/it]Running generate_until requests:  93%|█████████▎| 865/933 [2:44:40<09:31,  8.40s/it]Both `max_new_tokens` (=2048) and `max_length`(=2121) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  94%|█████████▎| 873/933 [2:46:16<09:27,  9.46s/it]Both `max_new_tokens` (=2048) and `max_length`(=2120) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  94%|█████████▍| 881/933 [2:47:51<08:50, 10.21s/it]Both `max_new_tokens` (=2048) and `max_length`(=2117) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  95%|█████████▌| 889/933 [2:49:27<07:51, 10.72s/it]Both `max_new_tokens` (=2048) and `max_length`(=2114) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  96%|█████████▌| 897/933 [2:50:28<05:52,  9.80s/it]Both `max_new_tokens` (=2048) and `max_length`(=2112) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  97%|█████████▋| 905/933 [2:50:28<03:12,  6.87s/it]Both `max_new_tokens` (=2048) and `max_length`(=2110) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  98%|█████████▊| 912/933 [2:50:41<02:24,  6.87s/it]Running generate_until requests:  98%|█████████▊| 913/933 [2:52:03<02:47,  8.38s/it]Both `max_new_tokens` (=2048) and `max_length`(=2108) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests:  99%|█████████▊| 921/933 [2:53:39<01:53,  9.44s/it]Both `max_new_tokens` (=2048) and `max_length`(=2100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)
Running generate_until requests: 100%|█████████▉| 929/933 [2:53:39<00:26,  6.61s/it]Running generate_until requests: 100%|██████████| 933/933 [2:53:39<00:00, 11.17s/it]
2025-10-22:15:36:36 INFO     [loggers.evaluation_tracker:280] Output path not provided, skipping saving results aggregated
hf (pretrained=Qwen/Qwen2.5-Math-7B), gen_kwargs: ({'max_gen_toks': 2048}), limit: None, num_fewshot: 0, batch_size: 8
|Tasks|Version|Filter|n-shot|  Metric   |   |Value |   |Stderr|
|-----|------:|------|-----:|-----------|---|-----:|---|-----:|
|aime |      0|none  |     0|exact_match|↑  |0.2272|±  |0.0137|

