2025-10-22:10:59:44 INFO     [__main__:450] Selected Tasks: ['aime']
2025-10-22:10:59:44 INFO     [evaluator:202] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-10-22:10:59:44 WARNING  [evaluator:214] generation_kwargs: {'max_gen_toks': 32767} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-10-22:10:59:44 INFO     [evaluator:240] Initializing hf model, with arguments: {'pretrained': 'Qwen/Qwen2.5-7B-Instruct'}
2025-10-22:10:59:44 WARNING  [accelerate.utils.other:513] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-10-22:10:59:44 INFO     [models.huggingface:156] Using device 'cuda:0'
2025-10-22:10:59:45 INFO     [models.huggingface:423] Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda:0'}
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:08<00:25,  8.65s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:15<00:15,  7.76s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:24<00:08,  8.11s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:33<00:00,  8.35s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:33<00:00,  8.26s/it]
2025-10-22:11:00:20 INFO     [evaluator:305] aime: Using gen_kwargs: {'until': ['Question:', '</s>', '<|im_end|>', '<|eot_id|>'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 32767}
2025-10-22:11:00:20 INFO     [evaluator:320] num_fewshot has been set to 0 for aime in its config. Manual configuration will be ignored.
2025-10-22:11:00:20 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-10-22:11:00:20 INFO     [api.task:434] Building contexts for aime on rank 0...
  0%|          | 0/933 [00:00<?, ?it/s] 25%|██▌       | 237/933 [00:00<00:00, 2368.05it/s] 56%|█████▋    | 526/933 [00:00<00:00, 2669.69it/s] 87%|████████▋ | 814/933 [00:00<00:00, 2764.47it/s]100%|██████████| 933/933 [00:00<00:00, 2732.09it/s]
2025-10-22:11:00:20 INFO     [evaluator:574] Running generate_until requests
Running generate_until requests:   0%|          | 0/933 [00:00<?, ?it/s]2025-10-22:11:00:20 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 1334, truncating to last 1 tokens. Some content will be lost.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Running generate_until requests:   0%|          | 1/933 [00:17<4:33:52, 17.63s/it]2025-10-22:11:00:38 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 524, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:   1%|          | 9/933 [00:33<49:35,  3.22s/it]  2025-10-22:11:00:53 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 427, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:   2%|▏         | 17/933 [00:48<38:14,  2.51s/it]2025-10-22:11:01:09 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 386, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:   3%|▎         | 25/933 [01:04<34:13,  2.26s/it]2025-10-22:11:01:25 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 336, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:   4%|▎         | 33/933 [01:20<32:10,  2.14s/it]2025-10-22:11:01:41 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 272, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:   4%|▍         | 41/933 [01:36<30:54,  2.08s/it]2025-10-22:11:01:56 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 261, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:   5%|▌         | 49/933 [01:51<30:03,  2.04s/it]2025-10-22:11:02:12 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 250, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:   6%|▌         | 57/933 [02:07<29:25,  2.02s/it]2025-10-22:11:02:28 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 235, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:   7%|▋         | 65/933 [02:23<28:55,  2.00s/it]2025-10-22:11:02:43 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 224, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:   8%|▊         | 73/933 [02:38<28:29,  1.99s/it]2025-10-22:11:02:59 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 219, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:   9%|▊         | 81/933 [02:54<28:07,  1.98s/it]2025-10-22:11:03:15 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 215, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  10%|▉         | 89/933 [03:10<27:47,  1.98s/it]2025-10-22:11:03:30 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 211, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  10%|█         | 97/933 [03:26<27:28,  1.97s/it]2025-10-22:11:03:46 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 207, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  11%|█▏        | 105/933 [03:41<27:10,  1.97s/it]2025-10-22:11:04:02 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 203, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  12%|█▏        | 113/933 [03:57<26:53,  1.97s/it]2025-10-22:11:04:18 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 201, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  13%|█▎        | 121/933 [04:13<26:36,  1.97s/it]2025-10-22:11:04:33 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 197, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  14%|█▍        | 129/933 [04:28<26:20,  1.97s/it]2025-10-22:11:04:49 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 195, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  15%|█▍        | 137/933 [04:44<26:04,  1.97s/it]2025-10-22:11:05:05 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 192, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  16%|█▌        | 145/933 [05:00<25:48,  1.96s/it]2025-10-22:11:05:20 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 189, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  16%|█▋        | 153/933 [05:16<25:32,  1.96s/it]2025-10-22:11:05:36 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 187, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  17%|█▋        | 161/933 [05:31<25:16,  1.96s/it]2025-10-22:11:05:52 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 183, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  18%|█▊        | 169/933 [05:47<25:00,  1.96s/it]2025-10-22:11:06:08 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 181, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  19%|█▉        | 177/933 [06:03<24:45,  1.96s/it]2025-10-22:11:06:23 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 178, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  20%|█▉        | 185/933 [06:18<24:29,  1.96s/it]2025-10-22:11:06:39 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 176, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  21%|██        | 193/933 [06:34<24:14,  1.97s/it]2025-10-22:11:06:55 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 175, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  22%|██▏       | 201/933 [06:50<23:58,  1.97s/it]2025-10-22:11:07:10 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 174, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  22%|██▏       | 209/933 [07:06<23:42,  1.97s/it]2025-10-22:11:07:26 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 170, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  23%|██▎       | 217/933 [07:21<23:26,  1.96s/it]2025-10-22:11:07:42 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 167, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  24%|██▍       | 225/933 [07:37<23:10,  1.96s/it]2025-10-22:11:07:58 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 165, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  25%|██▍       | 233/933 [07:53<22:54,  1.96s/it]2025-10-22:11:08:13 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 163, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  26%|██▌       | 241/933 [08:08<22:39,  1.96s/it]2025-10-22:11:08:29 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 161, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  27%|██▋       | 249/933 [08:24<22:23,  1.96s/it]2025-10-22:11:08:45 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 159, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  28%|██▊       | 257/933 [08:40<22:07,  1.96s/it]2025-10-22:11:09:00 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 158, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  28%|██▊       | 265/933 [08:56<21:51,  1.96s/it]2025-10-22:11:09:16 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 156, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  29%|██▉       | 273/933 [09:11<21:36,  1.96s/it]2025-10-22:11:09:32 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 155, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  30%|███       | 281/933 [09:27<21:20,  1.96s/it]2025-10-22:11:09:48 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 153, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  31%|███       | 289/933 [09:43<21:04,  1.96s/it]2025-10-22:11:10:03 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 152, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  32%|███▏      | 297/933 [09:58<20:48,  1.96s/it]2025-10-22:11:10:19 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 150, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  33%|███▎      | 305/933 [10:14<20:33,  1.96s/it]2025-10-22:11:10:35 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 148, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  34%|███▎      | 313/933 [10:30<20:17,  1.96s/it]2025-10-22:11:10:50 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 147, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  34%|███▍      | 321/933 [10:46<20:01,  1.96s/it]2025-10-22:11:11:06 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 146, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  35%|███▌      | 329/933 [11:01<19:46,  1.96s/it]2025-10-22:11:11:22 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 145, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  36%|███▌      | 337/933 [11:17<19:30,  1.96s/it]2025-10-22:11:11:38 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 144, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  37%|███▋      | 345/933 [11:33<19:14,  1.96s/it]2025-10-22:11:11:53 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 143, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  38%|███▊      | 353/933 [11:48<18:58,  1.96s/it]2025-10-22:11:12:09 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 142, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  39%|███▊      | 361/933 [12:04<18:43,  1.96s/it]2025-10-22:11:12:25 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 140, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  40%|███▉      | 369/933 [12:20<18:27,  1.96s/it]2025-10-22:11:12:40 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 139, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  40%|████      | 377/933 [12:35<18:11,  1.96s/it]2025-10-22:11:12:56 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 138, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  41%|████▏     | 385/933 [12:51<17:56,  1.96s/it]2025-10-22:11:13:12 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 137, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  42%|████▏     | 393/933 [13:07<17:40,  1.96s/it]2025-10-22:11:13:28 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 136, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  43%|████▎     | 401/933 [13:23<17:24,  1.96s/it]2025-10-22:11:13:43 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 135, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  44%|████▍     | 409/933 [13:38<17:08,  1.96s/it]2025-10-22:11:13:59 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 134, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  45%|████▍     | 417/933 [13:54<16:53,  1.96s/it]2025-10-22:11:14:15 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 132, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  46%|████▌     | 425/933 [14:10<16:37,  1.96s/it]2025-10-22:11:14:30 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 131, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  46%|████▋     | 433/933 [14:25<16:21,  1.96s/it]2025-10-22:11:14:46 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 130, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  47%|████▋     | 441/933 [14:41<16:05,  1.96s/it]2025-10-22:11:15:02 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 130, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  48%|████▊     | 449/933 [14:57<15:50,  1.96s/it]2025-10-22:11:15:17 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 129, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  49%|████▉     | 457/933 [15:13<15:34,  1.96s/it]2025-10-22:11:15:33 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 127, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  50%|████▉     | 465/933 [15:28<15:18,  1.96s/it]2025-10-22:11:15:49 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 126, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  51%|█████     | 473/933 [15:44<15:02,  1.96s/it]2025-10-22:11:16:05 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 125, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  52%|█████▏    | 481/933 [16:00<14:47,  1.96s/it]2025-10-22:11:16:20 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 124, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  52%|█████▏    | 489/933 [16:15<14:31,  1.96s/it]2025-10-22:11:16:36 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 123, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  53%|█████▎    | 497/933 [16:31<14:15,  1.96s/it]2025-10-22:11:16:52 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 122, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  54%|█████▍    | 505/933 [16:47<14:00,  1.96s/it]2025-10-22:11:17:07 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 121, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  55%|█████▍    | 513/933 [17:02<13:44,  1.96s/it]2025-10-22:11:17:23 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 121, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  56%|█████▌    | 521/933 [17:18<13:28,  1.96s/it]2025-10-22:11:17:39 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 120, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  57%|█████▋    | 529/933 [17:34<13:13,  1.96s/it]2025-10-22:11:17:54 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 119, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  58%|█████▊    | 537/933 [17:50<12:57,  1.96s/it]2025-10-22:11:18:10 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 118, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  58%|█████▊    | 545/933 [18:05<12:41,  1.96s/it]2025-10-22:11:18:26 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 117, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  59%|█████▉    | 553/933 [18:21<12:26,  1.96s/it]2025-10-22:11:18:42 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 116, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  60%|██████    | 561/933 [18:37<12:10,  1.96s/it]2025-10-22:11:18:57 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 115, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  61%|██████    | 569/933 [18:52<11:54,  1.96s/it]2025-10-22:11:19:13 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 114, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  62%|██████▏   | 577/933 [19:08<11:38,  1.96s/it]2025-10-22:11:19:29 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 113, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  63%|██████▎   | 585/933 [19:24<11:23,  1.96s/it]2025-10-22:11:19:44 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 112, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  64%|██████▎   | 593/933 [19:39<11:07,  1.96s/it]2025-10-22:11:20:00 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 111, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  64%|██████▍   | 601/933 [19:55<10:51,  1.96s/it]2025-10-22:11:20:16 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 110, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  65%|██████▌   | 609/933 [20:11<10:36,  1.96s/it]2025-10-22:11:20:32 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 109, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  66%|██████▌   | 617/933 [20:27<10:20,  1.96s/it]2025-10-22:11:20:47 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 109, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  67%|██████▋   | 625/933 [20:42<10:04,  1.96s/it]2025-10-22:11:21:03 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 107, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  68%|██████▊   | 633/933 [20:58<09:48,  1.96s/it]2025-10-22:11:21:19 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 106, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  69%|██████▊   | 641/933 [21:14<09:33,  1.96s/it]2025-10-22:11:21:34 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 106, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  70%|██████▉   | 649/933 [21:29<09:17,  1.96s/it]2025-10-22:11:21:50 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 105, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  70%|███████   | 657/933 [21:45<09:01,  1.96s/it]2025-10-22:11:22:06 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 104, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  71%|███████▏  | 665/933 [22:01<08:45,  1.96s/it]2025-10-22:11:22:21 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 103, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  72%|███████▏  | 673/933 [22:16<08:29,  1.96s/it]2025-10-22:11:22:37 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 102, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  73%|███████▎  | 681/933 [22:32<08:14,  1.96s/it]2025-10-22:11:22:53 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 101, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  74%|███████▍  | 689/933 [22:48<07:58,  1.96s/it]2025-10-22:11:23:08 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 100, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  75%|███████▍  | 697/933 [23:04<07:43,  1.96s/it]2025-10-22:11:23:24 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 99, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  76%|███████▌  | 705/933 [23:19<07:27,  1.96s/it]2025-10-22:11:23:40 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 98, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  76%|███████▋  | 713/933 [23:35<07:11,  1.96s/it]2025-10-22:11:23:56 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 97, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  77%|███████▋  | 721/933 [23:51<06:56,  1.96s/it]2025-10-22:11:24:11 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 96, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  78%|███████▊  | 729/933 [24:06<06:40,  1.96s/it]2025-10-22:11:24:27 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 96, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  79%|███████▉  | 737/933 [24:22<06:24,  1.96s/it]2025-10-22:11:24:43 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 95, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  80%|███████▉  | 745/933 [24:38<06:09,  1.96s/it]2025-10-22:11:24:58 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 93, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  81%|████████  | 753/933 [24:53<05:53,  1.96s/it]2025-10-22:11:25:14 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 92, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  82%|████████▏ | 761/933 [25:09<05:37,  1.96s/it]2025-10-22:11:25:30 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 91, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  82%|████████▏ | 769/933 [25:25<05:21,  1.96s/it]2025-10-22:11:25:46 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 91, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  83%|████████▎ | 777/933 [25:41<05:06,  1.96s/it]2025-10-22:11:26:01 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 89, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  84%|████████▍ | 785/933 [25:56<04:50,  1.96s/it]2025-10-22:11:26:17 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 89, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  85%|████████▍ | 793/933 [26:12<04:34,  1.96s/it]2025-10-22:11:26:33 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 87, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  86%|████████▌ | 801/933 [26:28<04:19,  1.96s/it]2025-10-22:11:26:48 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 85, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  87%|████████▋ | 809/933 [26:43<04:03,  1.96s/it]2025-10-22:11:27:04 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 84, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  88%|████████▊ | 817/933 [26:59<03:47,  1.96s/it]2025-10-22:11:27:20 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 82, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  88%|████████▊ | 825/933 [27:15<03:32,  1.96s/it]2025-10-22:11:27:35 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 81, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  89%|████████▉ | 833/933 [27:31<03:16,  1.96s/it]2025-10-22:11:27:51 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 80, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  90%|█████████ | 841/933 [27:46<03:00,  1.96s/it]2025-10-22:11:28:07 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 79, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  91%|█████████ | 849/933 [28:02<02:44,  1.96s/it]2025-10-22:11:28:23 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 77, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  92%|█████████▏| 857/933 [28:18<02:29,  1.96s/it]2025-10-22:11:28:38 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 76, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  93%|█████████▎| 865/933 [28:33<02:13,  1.96s/it]2025-10-22:11:28:54 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 74, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  94%|█████████▎| 873/933 [28:49<01:57,  1.96s/it]2025-10-22:11:29:10 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 73, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  94%|█████████▍| 881/933 [29:05<01:42,  1.96s/it]2025-10-22:11:29:25 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 70, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  95%|█████████▌| 889/933 [29:21<01:26,  1.96s/it]2025-10-22:11:29:41 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 67, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  96%|█████████▌| 897/933 [29:36<01:10,  1.96s/it]2025-10-22:11:29:57 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 65, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  97%|█████████▋| 905/933 [29:52<00:54,  1.96s/it]2025-10-22:11:30:13 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 63, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  98%|█████████▊| 913/933 [30:08<00:39,  1.96s/it]2025-10-22:11:30:28 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 61, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests:  99%|█████████▊| 921/933 [30:23<00:23,  1.96s/it]2025-10-22:11:30:44 WARNING  [models.huggingface:912] Left truncation applied. Original sequence length was 53, truncating to last 1 tokens. Some content will be lost.
Running generate_until requests: 100%|█████████▉| 929/933 [30:38<00:07,  1.92s/it]Running generate_until requests: 100%|██████████| 933/933 [30:38<00:00,  1.97s/it]
2025-10-22:11:31:05 INFO     [loggers.evaluation_tracker:280] Output path not provided, skipping saving results aggregated
hf (pretrained=Qwen/Qwen2.5-7B-Instruct), gen_kwargs: ({'max_gen_toks': 32767}), limit: None, num_fewshot: 0, batch_size: 8
|Tasks|Version|Filter|n-shot|  Metric   |   |Value|   |Stderr|
|-----|------:|------|-----:|-----------|---|----:|---|-----:|
|aime |      0|none  |     0|exact_match|↑  |    0|±  |     0|

